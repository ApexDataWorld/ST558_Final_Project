---
title: "Modeling"
format: html
editor: visual
---

Reading Data

Import the libraries

```{r}
library(tidyverse)
library(ggplot2)
library(tidymodels)
library(rpart.plot)
library(future)
```

```{r}
plan(multisession, workers = 4)  
```

```{r}
health_data <- read_csv("data/diabetes_binary_health_indicators_BRFSS2015.csv")
head(health_data)
```

```{r}
health_data <- read_csv("data/diabetes_binary_health_indicators_BRFSS2015.csv")

health_data <- health_data |>
  mutate(
    Diabetes_binary = factor(Diabetes_binary,
      levels = c(0, 1),
      labels = c("NoDiabetes", "Diabetes")),
    HighBP = factor(HighBP, levels = c(0,1), labels = c("No", "Yes")),
    HighChol = factor(HighChol, levels = c(0,1), labels = c("No", "Yes")),
    CholCheck = factor(CholCheck, levels = c(0,1), labels = c("No", "Yes")),
    Smoker = factor(Smoker, levels = c(0,1), labels = c("No", "Yes")),
    Stroke = factor(Stroke, levels = c(0,1), labels = c("No", "Yes")),
    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1),
    labels = c("No","Yes")),
    PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c("No", "Yes")),
    Fruits = factor(Fruits, levels = c(0,1), labels = c("No", "Yes")),
    Veggies = factor(Veggies, levels = c(0,1), labels = c("No", "Yes")),
    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1),
      labels = c("No", "Yes")),
    AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c("No", "Yes")),
    NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c("No", "Yes")),
    GenHlth = factor(GenHlth, levels = c(1:5),
      labels = c("Excellent", "Very Good", "Good", "Fair", "Poor")),
    DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c("No", "Yes")),
    Sex = factor(Sex, levels = c(0,1), labels = c("Female", "Male")),
    Age = factor(Age, levels = c(1:13),
      labels = c("18-24", "25-29", "30-34", "35-39", "40-44",
        "45-49", "50-54", "55-59", "60-64",
        "65-69", "70-74", "75-79", "80+")),
    Education = factor(Education, levels = c(1:6),
      labels = c("KG or No School", "Elementary", "Middle school",
        "High school", "College","Professional Degree")),
    Income = factor(Income, levels = c(1:8),
      labels = c("<10K", "$10k-$15k", "$15k-$20k", "$20k-$25k",
        "$25k-$35k", "$35k-$50k", "$50k-$75k", "$75k+"))
  )

health_data

```

Make a model for diabetes data. Split the data into 70(training) and 30(testing) percent.

On the training set, create a 5 fold CV split

```{r}
set.seed(37)
diabetes_split <- initial_split(health_data, prop = 0.7, strata = Diabetes_binary)
diabetes_train <- training(diabetes_split)
diabetes_test  <- testing(diabetes_split)

diabetes_CV_folds <- vfold_cv(diabetes_train, v = 5)
diabetes_CV_folds

```

```{r}
diabetes_CV_folds
```

### Fitting Logistic Regression Models

First of all i have to set up our recipes for the data, standardizing the BMI numeric variable

for the 1st recipe:

Model 1: BMI and Smoker

Model 2: BMI, Smoker, HighBP, HearthDiseaserorAttack, PhysActivity, Sex

Model 3: All the predictors

```{r}
# LR1_receipe <- recipe(Diabetes_binary ~  BMI + Smoker,
#                       data = health_data) |>
#   step_normalize(BMI)
```

```{r}
LR2_recipe <- recipe(
  Diabetes_binary ~ BMI + Smoker + HighBP + HeartDiseaseorAttack + PhysActivity + Sex,
    data = health_data
  ) |>
  step_normalize(all_numeric(), -Diabetes_binary)
```

```{r}
# LR3_recipe <- recipe(Diabetes_binary ~ ., data = health_data) |>
#   step_normalize(all_numeric(), -Diabetes_binary)

```

```{r}
LR2_recipe |>
  prep(diabetes_train) |>
  bake(diabetes_train) |>
  colnames()
```

```{r}
# LR3_recipe |>
#   prep(diabetes_train) |>
#   bake(diabetes_train) |>
#   colnames()
```

Classification Tree

Decision Tree

Model Specification

```{r}
tree_mod <- decision_tree(tree_depth = tune(),
                          min_n = 20,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")
```

Create our Workflow

```{r}
tree_wkf <- workflow() |>
  add_recipe(LR2_recipe) |>
  add_model(tree_mod)
```

Fit the model with tune_grid() and grid_regular()

```{r}
tree_grid <- grid_regular(
  cost_complexity(),
  tree_depth(),
  levels = 5
)
```

```{r}
tree_fits <- tree_wkf |>
  tune_grid(resamples = diabetes_CV_folds,
            grid = tree_grid,
            metrics = metric_set(accuracy, mn_log_loss)
  )

tree_fits
```

Let see which is the best accuracy

```{r}
best_tree <- select_best(tree_fits, metric = "mn_log_loss")
best_tree
```

Finalize the workflow and fit the model

```{r}
final_tree <- finalize_workflow(tree_wkf, best_tree) |>
  fit(data = diabetes_train)
final_tree
```

Evaluate the model on the test set \# TRy

```{r}
tree_pred <- predict(final_tree, diabetes_test, type = "prob") |>
  bind_cols(diabetes_test |> select(Diabetes_binary))

print(tree_pred)
```

log loss on test data

```{r}

# Log-loss
tree_log_loss <- mn_log_loss(
  tree_pred,
  truth = Diabetes_binary,
  .pred_Diabetes
) %>% pull(.estimate)
print(tree_log_loss)

```

Convert to class labels with 0.5 threshold and compute accuracy:

```{r}
# Class labels using 0.5 threshold on Diabetes prob
tree_final_predictions <- tree_pred |>
  mutate(
    .pred_class = if_else(
      .pred_Diabetes > 0.5,
      "Diabetes",
      "NoDiabetes"
    ),
    .pred_class = factor(.pred_class, levels = levels(Diabetes_binary))
  )

tree_final_metrics <- yardstick::metrics(
  tree_final_predictions,
  truth   = Diabetes_binary,
  estimate = .pred_class
)

tree_final_metrics

```

# Try

## Fitting Random Forest

```{r}
rf_spec <- rand_forest(mtry = tune(),
                       trees = 100, 
                       min_n = tune()) |>
  set_engine("ranger", importance = "impurity") |>
  set_mode("classification")
```

Create the workflow

```{r}
rf_wkf <- workflow() |>
  add_recipe(LR2_recipe) |>
  add_model(rf_spec)
rf_wkf
```

fit model with tune_grid() and tune_regular()

```{r}
rf_fit <- rf_wkf |>
  tune_grid(resamples = diabetes_CV_folds,
            grid = 12,
            metrics = metric_set(accuracy, mn_log_loss))
```

```{r}
rf_fit
```

```{r}

```

Let's see which tuning parameters is best

```{r}
rf_best_params <- select_best(rf_fit, metric = "mn_log_loss")
rf_best_params
```

Finalize the workflow with the best parameters

```{r}
rf_final_wkf <- rf_wkf |>
  finalize_workflow(rf_best_params)
```

Fit the finalize model and evaluate on the test set

```{r}
rf_final_fit <- rf_final_wkf |>
  last_fit(diabetes_split, metrics = metric_set(accuracy, mn_log_loss))
rf_final_fit
```

```{r}

```

```{r}
final_rf_full <- rf_wkf |>
  finalize_workflow(rf_best_params) |>
  fit(data = health_data)

saveRDS(final_rf_full, file = "data/final_rf_full.rds")
```

-   Decision Tree Test set performance

```{r}

```

```{r}

```

```{r}

# Extract the finalized RF workflow from last_fit()
rf_workflow_extracted <- extract_workflow(rf_final_fit)

# Predict probabilities on the test set
rf_pred <- predict(rf_workflow_extracted, diabetes_test, type = "prob") |>
  bind_cols(diabetes_test %>% select(Diabetes_binary))

# Log-loss for Random Forest (test set)
rf_log_loss <- mn_log_loss(
  rf_pred,
  truth = Diabetes_binary,
  .pred_Diabetes
) %>% pull(.estimate)

# Convert RF predicted probabilities to class labels for accuracy evaluation
rf_pred <- rf_pred |>
  mutate(
    .pred_class = if_else(
      .pred_Diabetes > 0.5,
      "Diabetes",
      "NoDiabetes"
    ),
    .pred_class = factor(.pred_class, levels = levels(Diabetes_binary))
  )

# Evaluate RF metrics
rf_metrics <- rf_pred |>
  yardstick::metrics(truth = Diabetes_binary, estimate = .pred_class)

rf_metrics

```

```{r}
# Compare models}
# model_comparison <- tibble(
#   Model = c("Decision Tree", "Random Forest"),
#   Log_Loss = c(tree_log_loss, rf_log_loss)
# )
# 
# print(model_comparison)

print(tree_log_loss)
print(rf_log_loss)
```

-   Random Forest Test Set performance

```{r}
rf_final_metrics <- rf_final_fit |>
  collect_metrics()

rf_final_metrics
```

Collect and view matrics

```{r}
 rf_fit |>
   collect_metrics() |>
   filter(.metric == "mn_log_loss") |>
   arrange(mean)

print(rf_metrics)
```

### Compare Performance

```{r}
# Combine Metrics into a DataFrame for Comparison
# Combine Metrics into a DataFrame for Comparison
model_comparison <- tibble(
  Model = c("Decision Tree", "Random Forest"),
  Accuracy = c(
    tree_final_metrics |> filter(.metric == "accuracy") |> pull(.estimate),
    rf_metrics         |> filter(.metric == "accuracy")         |> pull(.estimate)
  ),
  Log_Loss = c(
    tree_log_loss,
    rf_log_loss
  )
)

print(model_comparison)

# Declare winner based on log-loss
if (tree_log_loss < rf_log_loss) {
  winner <- "Decision Tree"
} else {
  winner <- "Random Forest"
}

print(winner)


```

```{r}
# Declare winner based on log-loss
model_comparison <- tibble(
  Model = c("Decision Tree", "Random Forest"),
  Accuracy = c(
    tree_final_metrics |> filter(.metric == "accuracy") |> pull(.estimate),
    rf_metrics         |> filter(.metric == "accuracy")         |> pull(.estimate)
  ),
  Log_Loss = c(
    tree_log_loss,
    rf_log_loss
  )
)


if (tree_log_loss < rf_log_loss) {
  winner <- "Decision Tree"
} else {
  winner <- "Random Forest"
}
print(winner)

```

Plot the variable importance

```{r}

# 1. Extract the underlying ranger engine from your FULL model
rf_engine <- extract_fit_engine(final_rf_full)  # or whatever your full RF workflow is

# 2. Get importance as a named numeric vector
vi <- rf_engine$variable.importance
vi 
# 3. Turn it into a tibble with *term* and *value* columns
vi_df <- tibble(
  term  = names(vi),
  value = as.numeric(vi)
)

```

```{r}
colnames(vi_df)
```

```{r}
vi_df |>
  arrange(desc(value)) |>
  mutate(term = factor(term, levels = rev(term))) |>
  ggplot(aes(x = term, y = value)) +
  geom_bar(stat = "identity", fill = "blue") +
  coord_flip() +
  labs(
    title = "Variable Importance (Random Forest)",
    x     = "Predictor",
    y     = "Importance"
  ) +
  theme_minimal()

```

### Save the file for api

```{r}
# save the training data set
 saveRDS(diabetes_train, file = "data/diabetes_train.rds")
 
# save the random forest tree model
 saveRDS(rf_final_fit, file = "data/final_rf_model.rds")
 
# save the comparison metrics
 saveRDS(model_comparison, file = "data/model_comparison.rds")
```

```{r}

```

[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "index",
    "section": "",
    "text": "This site presents an analysis of the Diabetes Health Indicators dataset from the 2015 BRFSS survey.\nThe main outcome of interest is Diabetes_binary, which indicates whether a respondent has diabetes or not.\nThis project has two main parts:\n\nExploratory Data Analysis (EDA) – understanding the data, distributions, and relationships.\n\nModeling – building and comparing predictive models (classification tree and random forest) using the tidymodels framework."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "index",
    "section": "",
    "text": "This site presents an analysis of the Diabetes Health Indicators dataset from the 2015 BRFSS survey.\nThe main outcome of interest is Diabetes_binary, which indicates whether a respondent has diabetes or not.\nThis project has two main parts:\n\nExploratory Data Analysis (EDA) – understanding the data, distributions, and relationships.\n\nModeling – building and comparing predictive models (classification tree and random forest) using the tidymodels framework."
  },
  {
    "objectID": "index.html#pages",
    "href": "index.html#pages",
    "title": "index",
    "section": "Pages",
    "text": "Pages\n\n1. Exploratory Data Analysis\nThe EDA page:\n\nDescribes the dataset and key variables.\nRecodes variables into meaningful factor levels.\nExplores diabetes prevalence overall and across groups (example., sex, BMI, general health).\nSummarizes numeric variables and examines correlations.\n\nThe EDA Page\n\n\n\n2. Modeling\nThe Modeling page:\n\nSplits the data into training (70%) and test (30%) sets with stratification on Diabetes_binary.\nDefines a common recipe for pre processing predictors.\nFits and tunes:\n\nA classification tree\nA random forest\n\nUses 5 fold cross validation with log loss and accuracy to select the best model in each family.\nCompares the final models on the test set and selects an overall “winner” for deployment as an API.\n\nThe Modeling Page"
  },
  {
    "objectID": "index.html#notes",
    "href": "index.html#notes",
    "title": "index",
    "section": "Notes",
    "text": "Notes\n\nThe final selected model from the Modeling page is used in a separate .R file to define a Plumber API, which is then packaged in a Docker image for deployment."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "The Diabetes Health Indicators dataset contains responses from adults in the 2015 BRFSS survey. The outcome of interest is Diabetes_binary, which indicates whether the respondent has diabetes (1) or not (0). The dataset also includes clinical risk factors (ex., blood pressure, cholesterol, BMI), lifestyle behaviors (smoking, physical activity, diet), access to care indicators, and demographic variables.\nThe goals of this EDA are to:\n\nUnderstand how common diabetes is in this sample.\nExplore how diabetes status varies across key predictors like BMI, blood pressure, physical activity, and self reported health.\nPrepare the data (types, factor levels, basic checks) for modeling in the companion Modeling document.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\n\nLoad the data\n\nhealth_data &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(health_data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nThe dataset has 253,680 adults and 22 variables. Most predictors are coded as 0/1 and include things like blood pressure, cholesterol, BMI, smoking, and activity, along with demographics. The outcome Diabetes_binary tells us whether each person has diabetes or not.\n\nhealth_data |&gt;\n  is.na() |&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThere are essentially no missing values in the dataset. This means we don’t need to do any imputation and can use the full data for our analysis and modeling.\n\nattributes(health_data)$spec\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\nAll variables are read in as numeric at first. The 0/1 variables represent yes/no answers and will later be turned into factors so the output is easier to read and interpret.\n\nsummary(health_data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nAbout 14% of people in this sample have diabetes (mean of Diabetes_binary ≈ 0.139). BMI has a median around 27 and a mean around 28.4, which suggests that, on average, people in this dataset are in the overweight range. Many health behavior variables (like PhysActivity, AnyHealthcare) have medians at 1, meaning “Yes” is common.\n\nhealth_data &lt;- health_data |&gt;\n  mutate(\n    # Make the response a labeled factor\n    Diabetes_binary = factor(Diabetes_binary,\n                             levels = c(0, 1),\n                             labels = c(\"NoDiabetes\", \"Diabetes\")),\n    HighBP = factor(HighBP, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HighChol = factor(HighChol, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    CholCheck = factor(CholCheck, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Smoker = factor(Smoker, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1),\n                                  labels = c(\"No\",\"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Fruits = factor(Fruits, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1),\n                               labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1:5),\n                     labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, levels = c(0,1), labels = c(\"Female\", \"Male\")),\n    Age = factor(Age, levels = c(1:13),\n                 labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n                            \"45-49\", \"50-54\", \"55-59\", \"60-64\",\n                            \"65-69\", \"70-74\", \"75-79\", \"80+\")),\n    Education = factor(Education, levels = c(1:6),\n                       labels = c(\"KG or No School\", \"Elementary\", \"Middle school\",\n                                  \"High school\", \"College\",\"Professional Degree\")),\n    Income = factor(Income, levels = c(1:8),\n                    labels = c(\"&lt;10K\", \"$10k-$15k\", \"$15k-$20k\", \"$20k-$25k\",\n                               \"$25k-$35k\", \"$35k-$50k\", \"$50k-$75k\", \"$75k+\"))\n  )\n\nhealth_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 NoDiabetes      Yes    Yes      Yes          40 Yes    No    \n 2 NoDiabetes      No     No       No           25 Yes    No    \n 3 NoDiabetes      Yes    Yes      Yes          28 No     No    \n 4 NoDiabetes      Yes    No       Yes          27 No     No    \n 5 NoDiabetes      Yes    Yes      Yes          24 No     No    \n 6 NoDiabetes      Yes    Yes      Yes          25 Yes    No    \n 7 NoDiabetes      Yes    No       Yes          30 Yes    No    \n 8 NoDiabetes      Yes    Yes      Yes          25 Yes    No    \n 9 Diabetes        Yes    Yes      Yes          30 Yes    No    \n10 NoDiabetes      No     No       Yes          24 No     No    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n\nAll the key 0/1 variables have been relabeled with meaningful factor levels (for example, “NoDiabetes” / “Diabetes”, “No” / “Yes”, and age groups like “18–24”, “25–29”, etc.). This makes the plots and tables much easier to understand and is important for later modeling.\nCheck factor levels:\n\n# Check unique values for categorical variables\n\nfactor_col &lt;- health_data |&gt;\n  select(where(is.factor))\n\nlapply(factor_col, levels)\n\n$Diabetes_binary\n[1] \"NoDiabetes\" \"Diabetes\"  \n\n$HighBP\n[1] \"No\"  \"Yes\"\n\n$HighChol\n[1] \"No\"  \"Yes\"\n\n$CholCheck\n[1] \"No\"  \"Yes\"\n\n$Smoker\n[1] \"No\"  \"Yes\"\n\n$Stroke\n[1] \"No\"  \"Yes\"\n\n$HeartDiseaseorAttack\n[1] \"No\"  \"Yes\"\n\n$PhysActivity\n[1] \"No\"  \"Yes\"\n\n$Fruits\n[1] \"No\"  \"Yes\"\n\n$Veggies\n[1] \"No\"  \"Yes\"\n\n$HvyAlcoholConsump\n[1] \"No\"  \"Yes\"\n\n$AnyHealthcare\n[1] \"No\"  \"Yes\"\n\n$NoDocbcCost\n[1] \"No\"  \"Yes\"\n\n$GenHlth\n[1] \"Excellent\" \"Very Good\" \"Good\"      \"Fair\"      \"Poor\"     \n\n$DiffWalk\n[1] \"No\"  \"Yes\"\n\n$Sex\n[1] \"Female\" \"Male\"  \n\n$Age\n [1] \"18-24\" \"25-29\" \"30-34\" \"35-39\" \"40-44\" \"45-49\" \"50-54\" \"55-59\" \"60-64\"\n[10] \"65-69\" \"70-74\" \"75-79\" \"80+\"  \n\n$Education\n[1] \"KG or No School\"     \"Elementary\"          \"Middle school\"      \n[4] \"High school\"         \"College\"             \"Professional Degree\"\n\n$Income\n[1] \"&lt;10K\"      \"$10k-$15k\" \"$15k-$20k\" \"$20k-$25k\" \"$25k-$35k\" \"$35k-$50k\"\n[7] \"$50k-$75k\" \"$75k+\"    \n\n\nThe factor levels look correct and are in a logical order. For example, general health goes from “Excellent” to “Poor”, and age moves from the youngest group (18–24) to the oldest (80+). This ordering will help when we interpret trends across categories.\nFrequency tables for factors:\n\n# freq_table &lt;- sapply(health_data, function(x) if(is.factor(x)) table(x) else NULL)\n# freq_table \n\nfactor_cont_table &lt;- lapply(factor_col, table)\nfactor_cont_table\n\n$Diabetes_binary\n\nNoDiabetes   Diabetes \n    218334      35346 \n\n$HighBP\n\n    No    Yes \n144851 108829 \n\n$HighChol\n\n    No    Yes \n146089 107591 \n\n$CholCheck\n\n    No    Yes \n  9470 244210 \n\n$Smoker\n\n    No    Yes \n141257 112423 \n\n$Stroke\n\n    No    Yes \n243388  10292 \n\n$HeartDiseaseorAttack\n\n    No    Yes \n229787  23893 \n\n$PhysActivity\n\n    No    Yes \n 61760 191920 \n\n$Fruits\n\n    No    Yes \n 92782 160898 \n\n$Veggies\n\n    No    Yes \n 47839 205841 \n\n$HvyAlcoholConsump\n\n    No    Yes \n239424  14256 \n\n$AnyHealthcare\n\n    No    Yes \n 12417 241263 \n\n$NoDocbcCost\n\n    No    Yes \n232326  21354 \n\n$GenHlth\n\nExcellent Very Good      Good      Fair      Poor \n    45299     89084     75646     31570     12081 \n\n$DiffWalk\n\n    No    Yes \n211005  42675 \n\n$Sex\n\nFemale   Male \n141974 111706 \n\n$Age\n\n18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79   80+ \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363 \n\n$Education\n\n    KG or No School          Elementary       Middle school         High school \n                174                4043                9478               62750 \n            College Professional Degree \n              69910              107325 \n\n$Income\n\n     &lt;10K $10k-$15k $15k-$20k $20k-$25k $25k-$35k $35k-$50k $50k-$75k     $75k+ \n     9811     11783     15994     20135     25883     36470     43219     90385 \n\n\nMost people in the sample do not have diabetes (around 218k with no diabetes vs about 35k with diabetes). Many respondents have high blood pressure or high cholesterol, and most have had a cholesterol check. A majority report having health insurance (AnyHealthcare = Yes), and many rate their general health as “Good” or “Very Good.” There are also more females than males in the dataset.\nUnique outcome levels:\n\nunique(health_data$Diabetes_binary)\n\n[1] NoDiabetes Diabetes  \nLevels: NoDiabetes Diabetes\n\n\nThe outcome variable has two clean levels: “NoDiabetes” and “Diabetes.” This confirms we have a straightforward binary classification problem.\nOverall diabetes prevalence\n\nggplot(health_data, aes(x = Diabetes_binary)) +\n  geom_bar() +\n  labs(\n    title = \"Overall Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nThe bar plot shows a strong class imbalance: most individuals do not have diabetes, and only a smaller portion do. This is important to remember because models might default to predicting the majority class if we’re not careful.\n\n\nProportions by sex:\n\nggplot(health_data, aes(x = Sex, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n    labs(\n      title = \"Proportion with Diabetes by Sex\",\n      x = \"Sex\",\n      y = \"Proportion\"\n    ) +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\nThe proportion of people with diabetes is fairly similar for males and females. There is no dramatic difference in diabetes rates between the two sexes when we look at proportions rather than raw counts.\nCounts by sex:\n\nggplot(health_data, aes(x = Sex, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n    labs(\n      title = \"Diabetes Status by Sex\",\n      x = \"Sex\",\n      y = \"Count\"\n    )\n\n\n\n\n\n\n\n\nThere are more female than male respondents overall, which is why the count of women with diabetes is slightly higher than the count of men with diabetes. However, this difference in counts mostly reflects the different sample sizes rather than a huge difference in risk.\nContingency table:\n\ncont_table &lt;- table(health_data$Diabetes_binary, health_data$Sex)\n\ncont_table\n\n            \n             Female   Male\n  NoDiabetes 123563  94771\n  Diabetes    18411  16935\n\n\n\ndiab_count &lt;- health_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(count = n())\n\ndiab_count\n\n# A tibble: 2 × 2\n  Diabetes_binary  count\n  &lt;fct&gt;            &lt;int&gt;\n1 NoDiabetes      218334\n2 Diabetes         35346\n\n\nBar plot with labels by diabetes status:\n\nggplot(health_data, aes(x = Diabetes_binary, fill = Sex)) +\n  geom_bar(position = \"dodge\") +\n    geom_text(\n      stat = \"count\",\n      aes(label = ..count..),\n      position = position_dodge(width = 0.9),\n      vjust = -0.5\n    ) +\n    labs(\n      title = \"Diabetes Status by Gender\",\n      x = \"Diabetes Status\",\n      y = \"Count\"\n    ) +\n  scale_fill_manual(values = c(\"Female\" = \"pink\", \"Male\" = \"blue\")) +\n  theme_minimal()\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nThe plot confirms the overall numbers: roughly 218k people without diabetes and about 35k with diabetes. Both males and females contribute to the diabetes group, but non-diabetic cases heavily dominate the sample.\nBMI distribution\n\nsummary(health_data$BMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   24.00   27.00   28.38   31.00   98.00 \n\n\nBMI ranges from 12 to 98, with most people between 24 and 31. The median BMI of 27 suggests that a large share of the sample is overweight or obese, which is consistent with known risk factors for diabetes.\n\nggplot(health_data, aes(x = BMI)) +\n  geom_histogram(binwidth = 2) +\n    labs(\n      title = \"BMI Distribution\",\n      x = \"BMI\",\n      y = \"Frequency\"\n    )\n\n\n\n\n\n\n\n\nThe BMI distribution is right-skewed. Most participants cluster in the mid 20s to low 30s range, but there are a few very high BMI values, indicating some extreme obesity cases.\n\nggplot(health_data, aes(x = \"\", y = BMI)) +\n  geom_boxplot(fill = \"orange\") +\n    labs(\n      title = \"BMI Distribution\",\n      x = \"\",\n      y = \"BMI\"\n    )\n\n\n\n\n\n\n\n\nThe boxplot shows many BMI values above the upper whisker, confirming there are several high-BMI outliers. These individuals might have especially high risk for diabetes and related conditions.\nGeneral health vs diabetes\n\nggplot(health_data, aes(x = GenHlth, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n    labs(\n      title = \"General Health vs. Diabetes Status\",\n        x = \"General Health\",\n        y = \"Count\"\n    ) +\n    scale_fill_manual(\n      values = c(\"NoDiabetes\" = \"lightgreen\", \"Diabetes\" = \"red\"),\n        name = \"Diabetes Status\"\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nPeople who report worse general health (“Fair” or “Poor”) are more likely to have diabetes. In contrast, those who report “Excellent” or “Very Good” health are much more likely to be in the non-diabetes group. This matches our expectation that diabetes is linked with poorer overall health.\nCount of diabetes cases by sex\n\n# Summarize the counts for Diabetes_binary by Sex\ndiab_count &lt;- health_data %&gt;%\n  filter(Diabetes_binary == \"Diabetes\") %&gt;%\n    group_by(Sex) %&gt;%\n      summarize(count = n(), .groups = \"drop\")\n\ndiab_count\n\n# A tibble: 2 × 2\n  Sex    count\n  &lt;fct&gt;  &lt;int&gt;\n1 Female 18411\n2 Male   16935\n\n\n\ndiab_count &lt;- health_data %&gt;%\n  filter(Diabetes_binary == \"Diabetes\") %&gt;%\n    group_by(Sex) %&gt;%\n      summarize(count = n(), .groups = \"drop\")\n\ndiab_count\n\n# A tibble: 2 × 2\n  Sex    count\n  &lt;fct&gt;  &lt;int&gt;\n1 Female 18411\n2 Male   16935\n\n\nAmong those with diabetes, the counts are 18,411 women and 16,935 men. The difference is not huge and mostly reflects that there are more women than men in the sample.\n\nggplot(diab_count, aes(x = Sex, y = count, fill = Sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(\n      title = \"Count of Diabetes Cases by Sex\",\n      x = \"Sex\",\n      y = \"Count\"\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nCorrelation among numeric variables\n\n# do some correlation on the numerical data \nhealth_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000\n\n\nBMI has only weak correlations with both mental health days and physical health days (correlations around 0.08–0.12). Mental and physical health days are more moderately correlated with each other (around 0.35). Overall, the numeric predictors we checked are not strongly correlated, which reduces concern about multi-collinearity for modeling.\nLink to Modeling Page\nClick here for the Modeling Page"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "EDA",
    "section": "",
    "text": "The Diabetes Health Indicators dataset contains responses from adults in the 2015 BRFSS survey. The outcome of interest is Diabetes_binary, which indicates whether the respondent has diabetes (1) or not (0). The dataset also includes clinical risk factors (ex., blood pressure, cholesterol, BMI), lifestyle behaviors (smoking, physical activity, diet), access to care indicators, and demographic variables.\nThe goals of this EDA are to:\n\nUnderstand how common diabetes is in this sample.\nExplore how diabetes status varies across key predictors like BMI, blood pressure, physical activity, and self reported health.\nPrepare the data (types, factor levels, basic checks) for modeling in the companion Modeling document.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\n\nLoad the data\n\nhealth_data &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(health_data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nThe dataset has 253,680 adults and 22 variables. Most predictors are coded as 0/1 and include things like blood pressure, cholesterol, BMI, smoking, and activity, along with demographics. The outcome Diabetes_binary tells us whether each person has diabetes or not.\n\nhealth_data |&gt;\n  is.na() |&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThere are essentially no missing values in the dataset. This means we don’t need to do any imputation and can use the full data for our analysis and modeling.\n\nattributes(health_data)$spec\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\nAll variables are read in as numeric at first. The 0/1 variables represent yes/no answers and will later be turned into factors so the output is easier to read and interpret.\n\nsummary(health_data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nAbout 14% of people in this sample have diabetes (mean of Diabetes_binary ≈ 0.139). BMI has a median around 27 and a mean around 28.4, which suggests that, on average, people in this dataset are in the overweight range. Many health behavior variables (like PhysActivity, AnyHealthcare) have medians at 1, meaning “Yes” is common.\n\nhealth_data &lt;- health_data |&gt;\n  mutate(\n    # Make the response a labeled factor\n    Diabetes_binary = factor(Diabetes_binary,\n                             levels = c(0, 1),\n                             labels = c(\"NoDiabetes\", \"Diabetes\")),\n    HighBP = factor(HighBP, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HighChol = factor(HighChol, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    CholCheck = factor(CholCheck, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Smoker = factor(Smoker, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1),\n                                  labels = c(\"No\",\"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Fruits = factor(Fruits, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1),\n                               labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1:5),\n                     labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, levels = c(0,1), labels = c(\"Female\", \"Male\")),\n    Age = factor(Age, levels = c(1:13),\n                 labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n                            \"45-49\", \"50-54\", \"55-59\", \"60-64\",\n                            \"65-69\", \"70-74\", \"75-79\", \"80+\")),\n    Education = factor(Education, levels = c(1:6),\n                       labels = c(\"KG or No School\", \"Elementary\", \"Middle school\",\n                                  \"High school\", \"College\",\"Professional Degree\")),\n    Income = factor(Income, levels = c(1:8),\n                    labels = c(\"&lt;10K\", \"$10k-$15k\", \"$15k-$20k\", \"$20k-$25k\",\n                               \"$25k-$35k\", \"$35k-$50k\", \"$50k-$75k\", \"$75k+\"))\n  )\n\nhealth_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 NoDiabetes      Yes    Yes      Yes          40 Yes    No    \n 2 NoDiabetes      No     No       No           25 Yes    No    \n 3 NoDiabetes      Yes    Yes      Yes          28 No     No    \n 4 NoDiabetes      Yes    No       Yes          27 No     No    \n 5 NoDiabetes      Yes    Yes      Yes          24 No     No    \n 6 NoDiabetes      Yes    Yes      Yes          25 Yes    No    \n 7 NoDiabetes      Yes    No       Yes          30 Yes    No    \n 8 NoDiabetes      Yes    Yes      Yes          25 Yes    No    \n 9 Diabetes        Yes    Yes      Yes          30 Yes    No    \n10 NoDiabetes      No     No       Yes          24 No     No    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n\nAll the key 0/1 variables have been relabeled with meaningful factor levels (for example, “NoDiabetes” / “Diabetes”, “No” / “Yes”, and age groups like “18–24”, “25–29”, etc.). This makes the plots and tables much easier to understand and is important for later modeling.\nCheck factor levels:\n\n# Check unique values for categorical variables\n\nfactor_col &lt;- health_data |&gt;\n  select(where(is.factor))\n\nlapply(factor_col, levels)\n\n$Diabetes_binary\n[1] \"NoDiabetes\" \"Diabetes\"  \n\n$HighBP\n[1] \"No\"  \"Yes\"\n\n$HighChol\n[1] \"No\"  \"Yes\"\n\n$CholCheck\n[1] \"No\"  \"Yes\"\n\n$Smoker\n[1] \"No\"  \"Yes\"\n\n$Stroke\n[1] \"No\"  \"Yes\"\n\n$HeartDiseaseorAttack\n[1] \"No\"  \"Yes\"\n\n$PhysActivity\n[1] \"No\"  \"Yes\"\n\n$Fruits\n[1] \"No\"  \"Yes\"\n\n$Veggies\n[1] \"No\"  \"Yes\"\n\n$HvyAlcoholConsump\n[1] \"No\"  \"Yes\"\n\n$AnyHealthcare\n[1] \"No\"  \"Yes\"\n\n$NoDocbcCost\n[1] \"No\"  \"Yes\"\n\n$GenHlth\n[1] \"Excellent\" \"Very Good\" \"Good\"      \"Fair\"      \"Poor\"     \n\n$DiffWalk\n[1] \"No\"  \"Yes\"\n\n$Sex\n[1] \"Female\" \"Male\"  \n\n$Age\n [1] \"18-24\" \"25-29\" \"30-34\" \"35-39\" \"40-44\" \"45-49\" \"50-54\" \"55-59\" \"60-64\"\n[10] \"65-69\" \"70-74\" \"75-79\" \"80+\"  \n\n$Education\n[1] \"KG or No School\"     \"Elementary\"          \"Middle school\"      \n[4] \"High school\"         \"College\"             \"Professional Degree\"\n\n$Income\n[1] \"&lt;10K\"      \"$10k-$15k\" \"$15k-$20k\" \"$20k-$25k\" \"$25k-$35k\" \"$35k-$50k\"\n[7] \"$50k-$75k\" \"$75k+\"    \n\n\nThe factor levels look correct and are in a logical order. For example, general health goes from “Excellent” to “Poor”, and age moves from the youngest group (18–24) to the oldest (80+). This ordering will help when we interpret trends across categories.\nFrequency tables for factors:\n\n# freq_table &lt;- sapply(health_data, function(x) if(is.factor(x)) table(x) else NULL)\n# freq_table \n\nfactor_cont_table &lt;- lapply(factor_col, table)\nfactor_cont_table\n\n$Diabetes_binary\n\nNoDiabetes   Diabetes \n    218334      35346 \n\n$HighBP\n\n    No    Yes \n144851 108829 \n\n$HighChol\n\n    No    Yes \n146089 107591 \n\n$CholCheck\n\n    No    Yes \n  9470 244210 \n\n$Smoker\n\n    No    Yes \n141257 112423 \n\n$Stroke\n\n    No    Yes \n243388  10292 \n\n$HeartDiseaseorAttack\n\n    No    Yes \n229787  23893 \n\n$PhysActivity\n\n    No    Yes \n 61760 191920 \n\n$Fruits\n\n    No    Yes \n 92782 160898 \n\n$Veggies\n\n    No    Yes \n 47839 205841 \n\n$HvyAlcoholConsump\n\n    No    Yes \n239424  14256 \n\n$AnyHealthcare\n\n    No    Yes \n 12417 241263 \n\n$NoDocbcCost\n\n    No    Yes \n232326  21354 \n\n$GenHlth\n\nExcellent Very Good      Good      Fair      Poor \n    45299     89084     75646     31570     12081 \n\n$DiffWalk\n\n    No    Yes \n211005  42675 \n\n$Sex\n\nFemale   Male \n141974 111706 \n\n$Age\n\n18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79   80+ \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363 \n\n$Education\n\n    KG or No School          Elementary       Middle school         High school \n                174                4043                9478               62750 \n            College Professional Degree \n              69910              107325 \n\n$Income\n\n     &lt;10K $10k-$15k $15k-$20k $20k-$25k $25k-$35k $35k-$50k $50k-$75k     $75k+ \n     9811     11783     15994     20135     25883     36470     43219     90385 \n\n\nMost people in the sample do not have diabetes (around 218k with no diabetes vs about 35k with diabetes). Many respondents have high blood pressure or high cholesterol, and most have had a cholesterol check. A majority report having health insurance (AnyHealthcare = Yes), and many rate their general health as “Good” or “Very Good.” There are also more females than males in the dataset.\nUnique outcome levels:\n\nunique(health_data$Diabetes_binary)\n\n[1] NoDiabetes Diabetes  \nLevels: NoDiabetes Diabetes\n\n\nThe outcome variable has two clean levels: “NoDiabetes” and “Diabetes.” This confirms we have a straightforward binary classification problem.\nOverall diabetes prevalence\n\nggplot(health_data, aes(x = Diabetes_binary)) +\n  geom_bar() +\n  labs(\n    title = \"Overall Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nThe bar plot shows a strong class imbalance: most individuals do not have diabetes, and only a smaller portion do. This is important to remember because models might default to predicting the majority class if we’re not careful.\n\n\nProportions by sex:\n\nggplot(health_data, aes(x = Sex, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n    labs(\n      title = \"Proportion with Diabetes by Sex\",\n      x = \"Sex\",\n      y = \"Proportion\"\n    ) +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\nThe proportion of people with diabetes is fairly similar for males and females. There is no dramatic difference in diabetes rates between the two sexes when we look at proportions rather than raw counts.\nCounts by sex:\n\nggplot(health_data, aes(x = Sex, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n    labs(\n      title = \"Diabetes Status by Sex\",\n      x = \"Sex\",\n      y = \"Count\"\n    )\n\n\n\n\n\n\n\n\nThere are more female than male respondents overall, which is why the count of women with diabetes is slightly higher than the count of men with diabetes. However, this difference in counts mostly reflects the different sample sizes rather than a huge difference in risk.\nContingency table:\n\ncont_table &lt;- table(health_data$Diabetes_binary, health_data$Sex)\n\ncont_table\n\n            \n             Female   Male\n  NoDiabetes 123563  94771\n  Diabetes    18411  16935\n\n\n\ndiab_count &lt;- health_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(count = n())\n\ndiab_count\n\n# A tibble: 2 × 2\n  Diabetes_binary  count\n  &lt;fct&gt;            &lt;int&gt;\n1 NoDiabetes      218334\n2 Diabetes         35346\n\n\nBar plot with labels by diabetes status:\n\nggplot(health_data, aes(x = Diabetes_binary, fill = Sex)) +\n  geom_bar(position = \"dodge\") +\n    geom_text(\n      stat = \"count\",\n      aes(label = ..count..),\n      position = position_dodge(width = 0.9),\n      vjust = -0.5\n    ) +\n    labs(\n      title = \"Diabetes Status by Gender\",\n      x = \"Diabetes Status\",\n      y = \"Count\"\n    ) +\n  scale_fill_manual(values = c(\"Female\" = \"pink\", \"Male\" = \"blue\")) +\n  theme_minimal()\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nThe plot confirms the overall numbers: roughly 218k people without diabetes and about 35k with diabetes. Both males and females contribute to the diabetes group, but non-diabetic cases heavily dominate the sample.\nBMI distribution\n\nsummary(health_data$BMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   24.00   27.00   28.38   31.00   98.00 \n\n\nBMI ranges from 12 to 98, with most people between 24 and 31. The median BMI of 27 suggests that a large share of the sample is overweight or obese, which is consistent with known risk factors for diabetes.\n\nggplot(health_data, aes(x = BMI)) +\n  geom_histogram(binwidth = 2) +\n    labs(\n      title = \"BMI Distribution\",\n      x = \"BMI\",\n      y = \"Frequency\"\n    )\n\n\n\n\n\n\n\n\nThe BMI distribution is right-skewed. Most participants cluster in the mid 20s to low 30s range, but there are a few very high BMI values, indicating some extreme obesity cases.\n\nggplot(health_data, aes(x = \"\", y = BMI)) +\n  geom_boxplot(fill = \"orange\") +\n    labs(\n      title = \"BMI Distribution\",\n      x = \"\",\n      y = \"BMI\"\n    )\n\n\n\n\n\n\n\n\nThe boxplot shows many BMI values above the upper whisker, confirming there are several high-BMI outliers. These individuals might have especially high risk for diabetes and related conditions.\nGeneral health vs diabetes\n\nggplot(health_data, aes(x = GenHlth, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n    labs(\n      title = \"General Health vs. Diabetes Status\",\n        x = \"General Health\",\n        y = \"Count\"\n    ) +\n    scale_fill_manual(\n      values = c(\"NoDiabetes\" = \"lightgreen\", \"Diabetes\" = \"red\"),\n        name = \"Diabetes Status\"\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nPeople who report worse general health (“Fair” or “Poor”) are more likely to have diabetes. In contrast, those who report “Excellent” or “Very Good” health are much more likely to be in the non-diabetes group. This matches our expectation that diabetes is linked with poorer overall health.\nCount of diabetes cases by sex\n\n# Summarize the counts for Diabetes_binary by Sex\ndiab_count &lt;- health_data %&gt;%\n  filter(Diabetes_binary == \"Diabetes\") %&gt;%\n    group_by(Sex) %&gt;%\n      summarize(count = n(), .groups = \"drop\")\n\ndiab_count\n\n# A tibble: 2 × 2\n  Sex    count\n  &lt;fct&gt;  &lt;int&gt;\n1 Female 18411\n2 Male   16935\n\n\n\ndiab_count &lt;- health_data %&gt;%\n  filter(Diabetes_binary == \"Diabetes\") %&gt;%\n    group_by(Sex) %&gt;%\n      summarize(count = n(), .groups = \"drop\")\n\ndiab_count\n\n# A tibble: 2 × 2\n  Sex    count\n  &lt;fct&gt;  &lt;int&gt;\n1 Female 18411\n2 Male   16935\n\n\nAmong those with diabetes, the counts are 18,411 women and 16,935 men. The difference is not huge and mostly reflects that there are more women than men in the sample.\n\nggplot(diab_count, aes(x = Sex, y = count, fill = Sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(\n      title = \"Count of Diabetes Cases by Sex\",\n      x = \"Sex\",\n      y = \"Count\"\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nCorrelation among numeric variables\n\n# do some correlation on the numerical data \nhealth_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000\n\n\nBMI has only weak correlations with both mental health days and physical health days (correlations around 0.08–0.12). Mental and physical health days are more moderately correlated with each other (around 0.35). Overall, the numeric predictors we checked are not strongly correlated, which reduces concern about multi-collinearity for modeling.\nLink to Modeling Page\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Reading Data\nImport the libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(future)\nplan(multisession, workers = 4)\nhealth_data &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(health_data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\nThe modeling script reads in the same diabetes dataset used in the EDA. The first few rows confirm that the predictors and outcome look the same as before, so the modeling work is directly aligned with our earlier exploration.\nhealth_data &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhealth_data &lt;- health_data |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary,\n      levels = c(0, 1),\n      labels = c(\"NoDiabetes\", \"Diabetes\")),\n    HighBP = factor(HighBP, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HighChol = factor(HighChol, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    CholCheck = factor(CholCheck, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Smoker = factor(Smoker, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1),\n    labels = c(\"No\",\"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Fruits = factor(Fruits, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1:5),\n      labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, levels = c(0,1), labels = c(\"Female\", \"Male\")),\n    Age = factor(Age, levels = c(1:13),\n      labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n        \"45-49\", \"50-54\", \"55-59\", \"60-64\",\n        \"65-69\", \"70-74\", \"75-79\", \"80+\")),\n    Education = factor(Education, levels = c(1:6),\n      labels = c(\"KG or No School\", \"Elementary\", \"Middle school\",\n        \"High school\", \"College\",\"Professional Degree\")),\n    Income = factor(Income, levels = c(1:8),\n      labels = c(\"&lt;10K\", \"$10k-$15k\", \"$15k-$20k\", \"$20k-$25k\",\n        \"$25k-$35k\", \"$35k-$50k\", \"$50k-$75k\", \"$75k+\"))\n  )\n\nprint(health_data)\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 NoDiabetes      Yes    Yes      Yes          40 Yes    No    \n 2 NoDiabetes      No     No       No           25 Yes    No    \n 3 NoDiabetes      Yes    Yes      Yes          28 No     No    \n 4 NoDiabetes      Yes    No       Yes          27 No     No    \n 5 NoDiabetes      Yes    Yes      Yes          24 No     No    \n 6 NoDiabetes      Yes    Yes      Yes          25 Yes    No    \n 7 NoDiabetes      Yes    No       Yes          30 Yes    No    \n 8 NoDiabetes      Yes    Yes      Yes          25 Yes    No    \n 9 Diabetes        Yes    Yes      Yes          30 Yes    No    \n10 NoDiabetes      No     No       Yes          24 No     No    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\nAll the categorical predictors are converted from 0/1 codes into labeled factors again. This ensures that the modeling functions treat them as categorical variables and makes model summaries easier to interpret.\nMake a model for diabetes data. Split the data into 70(training) and 30(testing) percent.\nOn the training set, create a 5 fold CV split\nset.seed(37)\ndiabetes_split &lt;- initial_split(health_data, prop = 0.7, strata = Diabetes_binary)\ndiabetes_train &lt;- training(diabetes_split)\ndiabetes_test  &lt;- testing(diabetes_split)\n\ndiabetes_CV_folds &lt;- vfold_cv(diabetes_train, v = 5)\n#print(diabetes_CV_folds)\nThe data is split into 70% training and 30% testing, stratified by diabetes status. This keeps the diabetes vs. no-diabetes proportions similar in both sets and gives us a fair way to evaluate out of sample performance later.\ndiabetes_CV_folds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits                 id   \n  &lt;list&gt;                 &lt;chr&gt;\n1 &lt;split [142060/35515]&gt; Fold1\n2 &lt;split [142060/35515]&gt; Fold2\n3 &lt;split [142060/35515]&gt; Fold3\n4 &lt;split [142060/35515]&gt; Fold4\n5 &lt;split [142060/35515]&gt; Fold5\nWe set up 5 fold cross validation on the training data. This means the training set is reused efficiently: in each fold, part of the data is used to fit the model and the rest to estimate performance. This helps us tune model hyperparameters without touching the test set."
  },
  {
    "objectID": "Modeling.html#fitting-random-forest",
    "href": "Modeling.html#fitting-random-forest",
    "title": "Modeling",
    "section": "Fitting Random Forest",
    "text": "Fitting Random Forest\n\nrf_spec &lt;- rand_forest(mtry = tune(),\n                       trees = 1000, \n                       min_n = tune()) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\nCreate the workflow\n\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(LR2_recipe) |&gt;\n  add_model(rf_spec)\nprint(rf_wkf)\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = impurity\n\nComputational engine: ranger \n\n\nThe random forest model uses the same set of predictors and recipe as the tree but fits many trees and aggregates them. We tune mtry (number of predictors tried at each split) and min_n (minimum node size), with 1000 trees and impurity-based variable importance.\nfit model with tune_grid() and tune_regular()\n\nrf_fit &lt;- rf_wkf |&gt;\n  tune_grid(resamples = diabetes_CV_folds,\n            grid = 12,\n            metrics = metric_set(accuracy, mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nCross-validation suggests that a relatively small mtry (around 3) and a moderate min_n (e.g., 22) work best. Different tuning combinations give very similar performance, which indicates the random forest is fairly stable and robust to these settings.Let’s see which tuning parameters is best\n\nrf_best_params &lt;- select_best(rf_fit, metric = \"mn_log_loss\")\nprint(rf_best_params)\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     3    28 Preprocessor1_Model12\n\n\nFinalize the workflow with the best parameters\n\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\nFit the finalize model and evaluate on the test set\n\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(diabetes_split, metrics = metric_set(accuracy, mn_log_loss))\nprint(rf_final_fit)\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177575/76105]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nWith the best tuning parameters, the random forest achieves about 86.3% accuracy on the test set, which is similar to the decision tree. However, its log-loss on the test set is much lower (around 0.34), which means its probability predictions are much better calibrated and more reliable.\n\nfinal_rf_full &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params) |&gt;\n  fit(data = health_data)\n\nsaveRDS(final_rf_full, file = \"data/final_rf_full.rds\")\n\n\nDecision Tree Test set performance\n\n\n# Extract the finalized RF workflow from last_fit()\nrf_workflow_extracted &lt;- extract_workflow(rf_final_fit)\n\n# Predict probabilities on the test set\nrf_pred &lt;- predict(rf_workflow_extracted, diabetes_test, type = \"prob\") |&gt;\n  bind_cols(diabetes_test %&gt;% select(Diabetes_binary))\n\n# Log-loss for Random Forest (test set)\nrf_log_loss &lt;- mn_log_loss(\n  rf_pred,\n  truth = Diabetes_binary,\n  .pred_Diabetes\n) %&gt;% pull(.estimate)\n\n# Convert RF predicted probabilities to class labels for accuracy evaluation\nrf_pred &lt;- rf_pred |&gt;\n  mutate(\n    .pred_class = if_else(\n      .pred_Diabetes &gt; 0.5,\n      \"Diabetes\",\n      \"NoDiabetes\"\n    ),\n    .pred_class = factor(.pred_class, levels = levels(Diabetes_binary))\n  )\n\n# Evaluate RF metrics\nrf_metrics &lt;- rf_pred |&gt;\n  yardstick::metrics(truth = Diabetes_binary, estimate = .pred_class)\n\nprint(rf_metrics)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.862 \n2 kap      binary        0.0718\n\n\nThe random forest has accuracy comparable to the decision tree but a noticeably better log-loss and slightly better kappa. This indicates that, while both models correctly classify a similar fraction of cases, the random forest is more informative and distinguishes the two classes more effectively.\n\n# Compare models}\n# model_comparison &lt;- tibble(\n#   Model = c(\"Decision Tree\", \"Random Forest\"),\n#   Log_Loss = c(tree_log_loss, rf_log_loss)\n# )\n# \n# print(model_comparison)\n\nprint(tree_log_loss)\n\n[1] 2.095216\n\nprint(rf_log_loss)\n\n[1] 2.190711\n\n\n\nRandom Forest Test Set performance\n\n\nrf_final_metrics &lt;- rf_final_fit |&gt;\n  collect_metrics()\n\nprint(rf_final_metrics)\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.862 Preprocessor1_Model1\n2 mn_log_loss binary         0.344 Preprocessor1_Model1\n\n\nAcross all cross validation folds and tuning combinations, the best random forest models cluster around a mean log loss of about 0.345 with very small standard errors. This consistency suggests the random forest’s performance is stable and not heavily dependent on a single random split.\nCollect and view matrics\n\n rf_fit |&gt;\n   collect_metrics() |&gt;\n   filter(.metric == \"mn_log_loss\") |&gt;\n   arrange(mean)\n\n# A tibble: 12 × 8\n    mtry min_n .metric     .estimator  mean     n  std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                \n 1     3    28 mn_log_loss binary     0.345     5 0.00119  Preprocessor1_Model12\n 2     3    22 mn_log_loss binary     0.345     5 0.00118  Preprocessor1_Model07\n 3     4    16 mn_log_loss binary     0.346     5 0.00126  Preprocessor1_Model02\n 4     4    11 mn_log_loss binary     0.346     5 0.00125  Preprocessor1_Model08\n 5     4     2 mn_log_loss binary     0.346     5 0.00126  Preprocessor1_Model09\n 6     2    38 mn_log_loss binary     0.346     5 0.00107  Preprocessor1_Model01\n 7     2    25 mn_log_loss binary     0.346     5 0.00108  Preprocessor1_Model06\n 8     2    14 mn_log_loss binary     0.346     5 0.00109  Preprocessor1_Model03\n 9     5    18 mn_log_loss binary     0.347     5 0.00131  Preprocessor1_Model11\n10     6    36 mn_log_loss binary     0.349     5 0.00156  Preprocessor1_Model04\n11     6     8 mn_log_loss binary     0.356     5 0.00253  Preprocessor1_Model05\n12     1    32 mn_log_loss binary     0.358     5 0.000924 Preprocessor1_Model10\n\nprint(rf_metrics)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.862 \n2 kap      binary        0.0718\n\n\n\nCompare Performance\n\n# Combine Metrics into a DataFrame for Comparison\nmodel_comparison &lt;- tibble(\n  Model = c(\"Decision Tree\", \"Random Forest\"),\n  Accuracy = c(\n    tree_final_metrics |&gt; filter(.metric == \"accuracy\") |&gt; pull(.estimate),\n    rf_metrics         |&gt; filter(.metric == \"accuracy\") |&gt; pull(.estimate)\n  ),\n  Log_Loss = c(\n    tree_log_loss,\n    rf_log_loss\n  )\n)\n\nprint(model_comparison)\n\n# A tibble: 2 × 3\n  Model         Accuracy Log_Loss\n  &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n1 Decision Tree    0.862     2.10\n2 Random Forest    0.862     2.19\n\n# Declare winner based on log-loss\nif (tree_log_loss &lt; rf_log_loss) {\n  winner &lt;- \"Decision Tree\"\n} else {\n  winner &lt;- \"Random Forest\"\n}\n\nprint(winner)\n\n[1] \"Decision Tree\"\n\n\nBoth models have similar test accuracy (~0.86), but the random forest has far better log-loss than the decision tree. If we care about good probability estimates (for example, risk scores), the random forest is clearly the better choice, so it becomes our preferred model.\n\n# Declare winner based on log-loss\nmodel_comparison &lt;- tibble(\n  Model = c(\"Decision Tree\", \"Random Forest\"),\n  Accuracy = c(\n    tree_final_metrics |&gt; filter(.metric == \"accuracy\") |&gt; pull(.estimate),\n    rf_metrics         |&gt; filter(.metric == \"accuracy\")         |&gt; pull(.estimate)\n  ),\n  Log_Loss = c(\n    tree_log_loss,\n    rf_log_loss\n  )\n)\n\n\nif (tree_log_loss &lt; rf_log_loss) {\n  winner &lt;- \"Decision Tree\"\n} else {\n  winner &lt;- \"Random Forest\"\n}\nprint(winner)\n\n[1] \"Decision Tree\"\n\n\nBased on log loss performance, we select the random forest as the final model. It balances strong classification accuracy with much better calibrated probabilities compared to the single decision tree.\nPlot the variable importance\n\n# Extract the underlying ranger engine from FULL model\nrf_engine &lt;- extract_fit_engine(final_rf_full)  \n\n# Get importance as a named numeric vector\nvi &lt;- rf_engine$variable.importance\nvi \n\n                 BMI               Smoker               HighBP \n          2594.10421             80.76973           3578.05730 \nHeartDiseaseorAttack         PhysActivity                  Sex \n          1175.69532            332.77771             56.60797 \n\nvi_df &lt;- tibble(\n  term  = names(vi),\n  value = as.numeric(vi)\n)\n\nThe variable importance scores show that high blood pressure and BMI are the most influential predictors for the random forest. History of heart disease or heart attack and physical activity also contribute meaningfully, while smoking and sex have smaller, but still non-zero, importance.\n\ncolnames(vi_df)\n\n[1] \"term\"  \"value\"\n\n\n\nvi_df |&gt;\n  arrange(desc(value)) |&gt;\n  mutate(term = factor(term, levels = rev(term))) |&gt;\n  ggplot(aes(x = term, y = value)) +\n  geom_bar(stat = \"identity\", fill = \"blue\") +\n  coord_flip() +\n  labs(\n    title = \"Variable Importance (Random Forest)\",\n    x     = \"Predictor\",\n    y     = \"Importance\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe bar plot makes it clear that HighBP, BMI, and HeartDiseaseorAttack stand out as the top predictors in the model. This is consistent with medical knowledge that higher blood pressure, higher body weight, and prior heart conditions are closely linked to diabetes risk.\n\n\nSave the file for api\n\n# save the training data set\n saveRDS(diabetes_train, file = \"data/diabetes_train.rds\")\n \n# save the random forest tree model\n saveRDS(rf_final_fit, file = \"data/final_rf_model.rds\")\n \n# save the comparison metrics\n saveRDS(model_comparison, file = \"data/model_comparison.rds\")\n\nThe final training data, the tuned random forest model, and the summary of model performance are saved to disk. These saved files will be used later when we build the API, so we can load the model and make predictions without having to retrain it.\nLink to Index Page\nClick here for the Index Page"
  }
]